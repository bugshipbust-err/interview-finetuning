{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b891ec-4a03-49a7-a585-071a16f5bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import transformers, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f65a29-2b17-4c03-9838-b13a102d4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c5afff22944c68abc30970f90fb0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sivakrishna/miniconda3/envs/test/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3c1d61-4aba-4182-9a85-3c46a23f0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf9a691-8730-47fb-8bcf-32eaf0baa345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"complete the sentence: tera naam kya \"\n",
    "generated_text = pipeline(prompt,\n",
    "                          max_length=32,\n",
    "                          do_sample=True, \n",
    "                          top_k=1, \n",
    "                          num_return_sequences=1,\n",
    "                          eos_token_id=tokenizer.eos_token_id,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6287e09d-4cdb-4b6a-a24c-fdacf33767a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete the sentence: tera naam kya _________ hai?\n",
      "a) tera naam kya hai?\n",
      "b) tera na\n"
     ]
    }
   ],
   "source": [
    "print(generated_text[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
