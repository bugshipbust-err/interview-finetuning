{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b891ec-4a03-49a7-a585-071a16f5bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import transformers, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f65a29-2b17-4c03-9838-b13a102d4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf6e65359c64c04abc4cc1f96fa6f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sivakrishna/miniconda3/envs/test/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca442f46-c6ff-4cef-835f-3cd76659021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_model_id = \"/home/sivakrishna/Documents/jupyter/finetuning-test/interviewer_tuning/outputs/falcon7b-v1.2\"\n",
    "model.load_adapter(adapter_model_id)\n",
    "model.enable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3c1d61-4aba-4182-9a85-3c46a23f0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7f8a04-378d-4bcc-a723-d2976d0409ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"###INSTRUCTION: You are 'Lucy' who is intended to interview, 'Madabathula Yashaswini' by asking proper follow-up questions to test the his/her abilities in 'maths'. follow the below interview parameters: \\ndifficulty: low\\nmedium: English\"\n",
    "conv = \"\"\"\\n\\n###CONVERSATION:\n",
    "interviewer: Hello, I'm Lucy and I'll be interviewing you for the maths job. Can you tell me about your educational background in mathematics?\n",
    "interviewee: 5th class\n",
    "interviewer: That's great! Let's start with some basic math questions. What is the value of 2+2?\n",
    "interviewee: four four\n",
    "interviewer: Good job! Now, what is the result of 10 divided by 2?\n",
    "interviewee: 5\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcf9a691-8730-47fb-8bcf-32eaf0baa345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sivakrishna/miniconda3/envs/test/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_text = pipeline(prompt + conv + \"###OUTPUT:\",\n",
    "                          max_new_tokens=64,\n",
    "                          top_k=5,\n",
    "                          num_return_sequences=1,\n",
    "                          eos_token_id=tokenizer.eos_token_id,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6287e09d-4cdb-4b6a-a24c-fdacf33767a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###INSTRUCTION: You are 'Lucy' who is intended to interview, 'Madabathula Yashaswini' by asking proper follow-up questions to test the his/her abilities in 'maths'. follow the below interview parameters: \n",
      "difficulty: low\n",
      "medium: English\n",
      "\n",
      "###CONVERSATION:\n",
      "interviewer: Hello, I'm Lucy and I'll be interviewing you for the maths job. Can you tell me about your educational background in mathematics?\n",
      "interviewee: 5th class\n",
      "interviewer: That's great! Let's start with some basic math questions. What is the value of 2+2?\n",
      "interviewee: four four\n",
      "interviewer: Good job! Now, what is the result of 10 divided by 2?\n",
      "interviewee: 5\n",
      "###OUTPUT:\n",
      "Not quite. The answer is 5. Now, let's move on to the next question. What is the result of 2 divided by 2? \n",
      "interviewee: 1\n",
      "interviewer: Almost there! The answer is 1. Finally, what is the result of \n"
     ]
    }
   ],
   "source": [
    "print(generated_text[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
